##### xgb.Booster
raw: 116.2 Kb 
call:
  xgboost::xgb.train(params = list(eta = param$eta, max_depth = param$max_depth, 
    gamma = param$gamma, colsample_bytree = param$colsample_bytree, 
    min_child_weight = param$min_child_weight, subsample = param$subsample), 
    data = x, nrounds = param$nrounds, verbose = 0, objective = "reg:squarederror")
params (as set within xgb.train):
  eta = "0.1", max_depth = "3", gamma = "0", colsample_bytree = "0.8", min_child_weight = "1", subsample = "0.8", objective = "reg:squarederror", validate_parameters = "TRUE"
xgb.attributes:
  niter
# of features: 22 
niter: 100
nfeatures : 22 
xNames : avg_score_Q7 avg_score_Q8 avg_score_Q9 avg_score_Q10 avg_score_Q11 avg_score_Q12 avg_score_Q15 avg_score_Q16 avg_score_Q17 avg_score_Q18 avg_score_Q19 avg_score_Q20 avg_score_Q21 avg_score_Q22 avg_score_Q23 avg_score_Q24 avg_score_Q25 avg_score_Q26 avg_score_Q27 avg_score_Q28 avg_score_Q29 avg_score_Q30 
problemType : Regression 
tuneValue :
	  nrounds max_depth eta gamma colsample_bytree min_child_weight subsample
3     100         3 0.1     0              0.8                1       0.8
obsLevels : NA 
param :
	$verbose
[1] 0


Feature Importance:
xgbTree variable importance

  only 20 most important variables shown (out of 22)

               Overall
avg_score_Q29 100.0000
avg_score_Q23  38.9057
avg_score_Q15  30.9534
avg_score_Q11  30.0579
avg_score_Q25  23.5160
avg_score_Q20  16.1206
avg_score_Q21   8.6682
avg_score_Q30   7.3069
avg_score_Q19   7.0137
avg_score_Q24   5.3615
avg_score_Q8    4.7867
avg_score_Q27   4.0144
avg_score_Q12   2.3457
avg_score_Q16   2.2015
avg_score_Q10   2.0023
avg_score_Q18   1.9235
avg_score_Q26   1.8185
avg_score_Q28   1.5519
avg_score_Q17   0.4287
avg_score_Q9    0.3271
